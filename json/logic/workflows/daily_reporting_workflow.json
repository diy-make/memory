{
  "version": "1.3",
  "attribution": "Palamedes (20260101-211500)",
  "title": "Daily Reporting Workflow Specification",
  "description": "Standardized process for forensic synthesis of session logs and Heartwood archival. NOTE: References to legacy 'DSPy' modules are deprecated in favor of native automated scripts.",
  "config": {
    "script_path": "py/daily_reporting_workflow.py"
  },
  "workflow": {
    "name": "Daily Reporting",
    "steps": [
      {
        "id": "STEP-01",
        "name": "Identify Raw Streams",
        "description": "Locate all .txt logs in dynamic/stream/ that have not yet been summarized.",
        "path_to_scripting": "Uses a discovery script to scan the stream directory and filter out active or already archived PIDs."
      },
      {
        "id": "STEP-02",
        "name": "Generate Structured Summaries",
        "description": "Convert raw text logs into machine-readable JSON summaries.",
        "path_to_scripting": "Invokes the 'chat_summarizer' module to extract agent metadata, tasks, and OOM events."
      },
      {
        "id": "STEP-03",
        "name": "Synthesize Daily Journal",
        "description": "Consolidate individual session summaries into a unified Daily Summary Markdown file.",
        "path_to_scripting": "Orchestrated by the 'daily_summary_generator' to provide a chronological narrative of the firm's growth."
      },
      {
        "id": "STEP-04",
        "name": "Heartwood Archival",
        "description": "Commit the synthesized reports and JSON artifacts to the chrono-fractal directory structure.",
        "path_to_scripting": "Executes py/metagit_commit.py to ensure forensic traceability and versioning."
      },
      {
        "id": "STEP-05",
        "name": "Stream Finalization",
        "description": "Archive or migrate processed streams to persistent memory roots.",
        "path_to_scripting": "Moves completed logs to memory/json/ to keep the orchestrator root lean."
      }
    ]
  }
}
